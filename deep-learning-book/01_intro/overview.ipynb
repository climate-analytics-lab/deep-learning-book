{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa485b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Deep Learning for Geo/Environmental sciences\n",
    "\n",
    "<center><img src=\"../logo_2.png\" alt=\"logo\" width=\"600\"/></center>\n",
    "\n",
    "<em>*Created with ChapGPT</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e09ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Lecture 2: Overview\n",
    "\n",
    " - What is Machine Learning? \n",
    "   - One snarky answer and three increasingly useful ones!\n",
    " - Different classes of ML algorithms\n",
    " - What is Deep Learning?\n",
    " - ML for the GeoSciences\n",
    " - Ethical machine learning\n",
    "\n",
    "\n",
    "<em>*Roughly following Chapter 1 of UDL</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437043b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<center><img src=\"_images/machine_learning_2x.png\" alt=\"xkcd machine learning\" width=\"600\"/></center>\n",
    "\n",
    "<em>*XKCD 1838</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7cb06-7ed1-4bf6-a176-bcadbcbf9876",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<center><img src=\"_images/scatterplot_matrix.png\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da4045-7caf-4fbf-850d-50bbe6301a7a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Machine learning can also be thought of as high-dimensional statistics. We are looking to distill key features and information directly from the data. \"Machine Learning: A probabilistic perspective\" by Kevin Murphy is a great source for this point of view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfa44b-6c94-46f5-9848-6db304c80ed5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<center><img src=\"_images/ML_paradigm.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ec7c2-6ff2-404d-8ff8-dc4c9b8b8f34",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "This is true for science as well as programming. Rather than positing a functional form based on a scientific hypothesis, we provide 'answers/labels' along with our data in order to discern rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a6764",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<center><img src=\"_images/AI_subsets.png\" width=\"800\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411380c-97eb-4865-881e-af4e23eba3dc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Machine learning is a subset of the broader field of Artificial Intelligence first imagined by Alan Turing. It ecompases a range of different tasks, and at present represents the majority of AI research. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ef594",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Different classes of ML\n",
    "\n",
    "<center><img src=\"_images/ML_overview.png\" alt=\"ML Overview schematic\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d817429-ab30-4254-99be-30334e12e4ca",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "In addition, supervised learning can include object detection and image segmentation. Unsupervised learning also includes self-supervised learning in which we use inductive biases to encourage certain desirable behaviours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c3ce5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Supervised techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b197254",
   "metadata": {},
   "source": [
    "In its simplest form supervised learning involves learning a mapping from input data to output labels. This can be a regression problem, where we predict a continuous value, or a classification problem, where we predict a discrete value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379005f2",
   "metadata": {},
   "source": [
    "<center><img src=\"_images/supervised_regression.jpg\" alt=\"supervised learning\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe51a58",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258014e8-70c8-48f8-92b6-c73cdf37d584",
   "metadata": {},
   "source": [
    "<center><img src=\"_images/supervised_general.jpg\" alt=\"supervised learning\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29b785",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb9c50",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Regression and classification share a common toolset:\n",
    " - Linear models (including LASSO, ridge, SVM etc)\n",
    " - Decision tree and ensemble based\n",
    " - Gaussian process\n",
    " - Neural network (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a671e0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Image detection / segmentation can be done using 'traditional' image processing techniques such as edge-finding and watershedding, but are increasingly primarily done with Deep NNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7433e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised techniques - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8cbe7c",
   "metadata": {},
   "source": [
    "These deep learning approaches allow much more complex relationships to be learned in much higher dimensional data, but require a lot more data and computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd3d8a",
   "metadata": {},
   "source": [
    "<center><img src=\"_images/advanced_supervised.jpg\" alt=\"supervised learning\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8cbb7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Unsupervised techniques - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc3202-859b-4c8d-a020-4fec17a26179",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Clustering is a classical problem with many possible approaches depending on the dataset size and dimensionality:\n",
    " - k-means\n",
    " - DBSCAN\n",
    " - Gaussian mixture models\n",
    " - Aglomorotive clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c164e42-339c-4db2-8f4a-d29bea7c8dea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Unsupervised techniques - dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7004c9e",
   "metadata": {},
   "source": [
    "Many real-life systems exhibit high-dimensional behavior, but the underlying dynamics are often much lower - including the human face. It's possible to describe most of the variations in any face with just a few dozen numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08153d62",
   "metadata": {},
   "source": [
    "<center><img src=\"_images/dimensionality_reduction.jpg\" alt=\"supervised learning\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f009da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Unsupervised techniques - dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea918e1b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Many dimensionality reduction techniques exist:\n",
    " - Principle component analysis (PCA) / empirical orthogonal functions (EOF)\n",
    " - Kernel PCA\n",
    " - Density estimation\n",
    " - Gaussian mixture models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a1dd2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unsupervised techniques - dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4c7bf-1282-427d-8704-51fc62bc68e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "(Deep) NNs provide many other ways of learning underlying symetries in data, including self-supervised and semi-supervised approaches. If such symetries are learnt probabilistically then we call sampling from those models 'generative'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc930c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"_images/generative_model.jpg\" alt=\"supervised learning\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e00d5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a0816",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It turns out that many real-world datasets exhibit this lower intrinsic dimensionality, and that the underlying symetries can be effectively learnt by a Deep NN. Jointly learning these symetries with associated textual context (using e.g. CLIP) is the secret behind text-to-image generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85b3a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"_images/generative_model_samples.jpg\" alt=\"supervised learning\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb974de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f5a5a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When constructed in a certain way, it is possible to interpolate between different samples in the latent space of the model (more on this later). This allows for the generation of new samples that are not in the training set - and some funky images!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea373b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"_images/latent_space_example.jpg\" alt=\"latent space exploration\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd7a03",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683330ba",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Reinforcement learning is somewhat different - it aims to teach an agent how to behave in a dynamic environment to maximise some abstract, or delayed, reward.\n",
    "\n",
    "From Wikipedia:\n",
    "\n",
    "> It differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) with the goal of maximizing the long term reward, whose feedback might be incomplete or delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30208f84",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e11ed",
   "metadata": {},
   "source": [
    "These approaches are what underpin the success in playing Chess, Go and other games and seen as promising approaches for real world agents and robots, but training can be very fiddly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e731a4",
   "metadata": {},
   "source": [
    "<center><img src=\"_images/reinforcement_learning_policy.jpg\" alt=\"policy network example\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217fb0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What is deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625e1bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The phrase 'Deep learning' relates to the use of deep neural networks (10-100 layers) for a given machine learning task. It has become synonymous with many aspects of machine learning because of these models flexibility and performance across a wide range of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1719b50",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In this course we will mostly focus on these models because of their flexibility, and some of the unique challenges in training and using them in scientific applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394631fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Why use deep networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec8d44",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The *universal approximation theorem* tells us that any continuous 1D function can be approximated by an infinitely wide shallow Neural Network. So why go deeper?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7684495-615a-49f3-b30a-23b526a5928d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"_images/shallow_network.png\" alt=\"shallow network\" width=600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11d1f4-379f-4adc-9f21-35f550add8d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Why use deep networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17e297",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "While shallow NNs can be very effective regressors, it turns out that they can be impractical for some functions - requiring enourmous numbers of hidden units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc8b83",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In fact, some functions can be modelled much more efficiently by increasing the number of layers, rather than the width of the layers - particularly those with large numbers of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28fbc52-9ea6-4b50-8dc0-be4f4231b1ae",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"_images/deep_network.png\" alt=\"deep network\" width=600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753bfa5d-7731-4a15-b7b6-af148834cb2a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Note, we won't actually draw out deep networks like this because drawing all the links becomes very tedious! Rather we schematically draw out the structure with the main focus being representing the shape of the matrices in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4900da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Why use deep networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120d7b0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "Historically it was challenging to train deep networks because of the relatively larger number of parameters required to get good results. GPUs made this much less of a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a380da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "They became especially prevalent in modelling imagery because of the high dimensional input space, and the advent of convolutional layers which encode powerful inductive biases (even without training). We'll discuss these more later in the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecde437",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Practically it has been found that deep networks both train more easily, and generalize better than shallow ones. This is likely due to over-parameterization, but is not well understood and we'll also return to the topic at the end of the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0e01b-75b6-4a7b-9f4d-5e3c4c4e4884",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Why use deep networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30afc87f-01e1-48ec-930e-b078eb0ba1af",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "More prosaicly, they work! Deep NNs are the core of almost all of the most recent successes in AI and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce78dc-fbe4-459e-8492-18051c24182c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "While the theoretical understanding is not as mature for these structures they have repeatadly demonstrated their utility in a wide variety of tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed27bf-0253-47a3-b42d-64d37c6b7333",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Hence, constructing and working with these models is often more akin to engineering than science. Which is why this course will focus on hands-on experience over theoretical underpinning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86225e78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Machine Learning in Environmental and Geo-sciences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e27dd-8b10-4367-ad74-788624ed9ca6",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The environmental and geo sciences are well poised to leverage these advances\n",
    "\n",
    "<center><img src=\"_images/Reichstein_et_al.png\" alt=\"Overview of data challenges in Geo\" width=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832922d-b2aa-4b06-a1ee-af3ed7a9d084",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Climate - Ocean - Atmosphere Program (COAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b4b02-1fcb-4ed6-9f09-eb6de41ee135",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This is the section I know best, but also seems to be at the forefront currently, at least in applying big deep learning models. \n",
    "\n",
    "Examples include:\n",
    " - Data-driven weather models that beat the state-of-the-art physical models\n",
    " - New ML parameterizations that allow representation of more detailed physical processes\n",
    " - Large and broad efforts to better leverage large volumes of remote sensing data\n",
    " - Promising new approaches for assimilating these observations into hybrid-physical models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47f0ac-a613-43ae-b48c-c0bcdef4ba0e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Some relevant literature:\n",
    " - https://royalsocietypublishing.org/toc/rsta/2021/379/2194\n",
    " - https://iopscience.iop.org/article/10.1088/1748-9326/ab4e55\n",
    " - https://www.nature.com/articles/s41586-019-0912-1#Sec17\n",
    " - +One of the other big review papers and some specific examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253542a-e103-439d-bc99-21315944e4dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Climate - Ocean - Atmosphere Program (COAP)\n",
    "\n",
    "Later in the course we will reproduce and explore ClimateBench - a climate model emulation benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d522ed-e998-4117-9704-3d0f902f9399",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We will also look at techniques for unsupervised learning of satellite imagery\n",
    "\n",
    "<center><img src=\"_images/satellite_clusters.png\" alt=\"satellite clusters\" width=600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac658f09-04f4-4dd6-add6-d2061ceab92e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Geosciences of the Earth, Oceans and Planets (GEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b279f8-a90d-41c7-b5cc-ccd082ed32bb",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Probably the most statistically literate field, Geo has been leverage ML approaches for some time (and invented Gaussian process regression!) and there have been plenty of applications of these approaches to date:\n",
    " - High resolution subsurface structure using active seismic sources in exploration geophysics\n",
    "   - Pioneered the development of Physics Informed Neural Networks (PINNs)\n",
    " - Microearthquake detection, and earthquake early warning?\n",
    " - Large spatial scale remote sensing imagery classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed362f-b25f-4d71-ab68-b69627c7a35e",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "What did I miss?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4df20a-1e5b-4df6-abf6-7ba51b7b4d8a",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    " - https://geo-smart.github.io/usecases\n",
    " - https://www.science.org/doi/10.1126/science.abm4470\n",
    " - https://www.science.org/doi/10.1126/sciadv.1700578\n",
    " - https://arxiv.org/abs/2006.11894\n",
    " - https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021RG000742\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a565dd-b16d-42dc-aaa8-6d8d7f4eb012",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Ocean Biosciences Program (OBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142ec1f-aa88-403d-99be-fd83781b0429",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Again, lots of potential applications in this data-rich field:\n",
    " - Detection and classification of ocean life at all scales in remote and sub-surface imagery\n",
    " - Improved modelling and network analysis\n",
    " - New opportunities to harness large volumes of acoustic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd298237-71fb-427b-8fd4-620f96b89655",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We will explore this last example in detail later in the course - applying CNNs to the detection of whale song just off the coast of California"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947dee3-4059-4522-895c-d6e712db0336",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"_images/whale_calls.png\" alt=\"whale calls\" width=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c59ed0-9e8f-490a-973b-f5b89eb22d11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "And to the detection of Plankton in under-water imagery:\n",
    "\n",
    "<center><img src=\"_images/plankton_examples.gif\" alt=\"whale calls\" width=600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78beaedc-44c2-4847-b62a-348af5619ed4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    " - https://spo.nmfs.noaa.gov/sites/default/files/TMSPO199_0.pdf\n",
    " - https://ieeexplore.ieee.org/abstract/document/7404607\n",
    " - Michaela's paper?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd3e0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Ask for examples from the students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39285d15-aff5-4113-9d33-bd8cea9bcb25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ethics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354c42d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Machine learning is already a powerful tool, and could potentially become as important as the steam engine and elecrictiy, so it is important to consider the ethical implications of its use. \n",
    "\n",
    " - Bias and Fairness\n",
    " - Explainability \n",
    " - Privacy and Transparency\n",
    " - Concentrating Power\n",
    " - Existential Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c8191-2c61-40a0-9087-67d6d4496dd4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bias and Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d393de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Bias refers to the systematic errors or prejudices that can be present in the data used to train machine learning models. It can lead to biased predictions and unfair outcomes, perpetuating and potentially exacerbating existing inequalities and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188ded7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fairness is the concept of ensuring that machine learning models do not discriminate against individuals or groups based on protected attributes such as race, gender, or age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b58ccb5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fairness in machine learning requires careful consideration of the data used for training, the features selected, and the algorithms employed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed61cec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Techniques such as data preprocessing, feature engineering, and algorithmic adjustments can be used to mitigate bias and promote fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94bb916",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Privacy and Transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817781ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transparency and accountability are key in promoting fairness and addressing bias in machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5efba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Especially when deployed in public functions transparency is crucial. The data that was used to train the model, and the way the model is used to make decisions should be clear and understandable to the people affected by it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21d166",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another important ethical consideration in machine learning is privacy. Machine learning models can be trained on sensitive data, such as personal information or medical records, which raises concerns about data privacy and security.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3c411",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Ongoing research and collaboration are essential to develop best practices and guidelines for addressing bias and fairness in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb168b7-7677-4c2d-936b-0dad2a89996f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93f7b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Explainability is a critical aspect of machine learning models, especially in domains where decisions have significant consequences. It refers to the ability to understand and interpret the reasoning behind a model's predictions or decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545cf80d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Explainable models build trust and confidence in the predictions made by the model. Users are more likely to accept and adopt a model if they can understand how it arrives at its conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b7f25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Complexity: As models become more complex, their explainability decreases. Deep learning models, for example, are often considered black boxes due to their intricate architectures. There is often a trade-off between model performance and explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cc245",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- Research is ongoing to develop more robust and reliable techniques for explainability in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab05fb6-bf43-4e6c-827a-7c6eb7442f37",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Concentrating Power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cfbeb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Large technology companies have invested a huge amount of money in developing the latest machine learning models, but it's not altruistic. They are looking to leverage these models to increase their profits and market share."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf394f0a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Even the latest efforts for ML climate and weather models are primarily driven by buisness interests and it's important to consider the risk of concentrating power in the hands of a few companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe48d71",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - The same can be said about large physical climate models, but at least there is a large community of researchers and a lot of transparency in the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8661545",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Ideally ML emulators can democratize access to these models, but it's important to consider the potential for misuse and abuse of these technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8be3c-7803-47b1-8d0b-e90f6a6c9d27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Existential Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776cc1f",
   "metadata": {},
   "source": [
    "<center><img src=\"_images/terminator.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5a5fc-0cca-46cc-8e70-40b5528acf49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Next week - data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9afdbe-6d5f-4935-b269-982c82a929b3",
   "metadata": {},
   "source": [
    "Be sure to refresh yourself on the basics of Python and numpy before then. Some good resources are:\n",
    " - [An Introduction to Earth and Environmental Data Science](https://earth-env-data-science.github.io/intro.html)\n",
    " - Software Carpentry Python course: https://swcarpentry.github.io/python-novice-inflammation/\n",
    " - Potentially also their data analysis based course: https://swcarpentry.github.io/python-novice-gapminder/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
