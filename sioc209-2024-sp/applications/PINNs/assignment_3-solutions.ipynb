{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Solving the wave equation using PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will be exploring Physics-Informed Neural Networks (PINNs) and building up to solving the 2d wave equation. The wave equation is a second-order partial differential equation that describes how waves propagate over time. It is used in many fields, including acoustics, optics, and seismology.\n",
    "\n",
    "#### Objectives:\n",
    "- Understand the wave equation and its applications.\n",
    "- Develop a Physics-Informed Neural Network (PINN) to solve the wave equation.\n",
    "- Explore the impact of different hyperparameters on the performance of the PINN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: investigate how well the PINN scales to higher frequency oscillations (20 marks)\n",
    "\n",
    "\n",
    "The first task is to investigate how well the PINN **scales** to higher frequency oscillations and what can be done to improve its convergence.\n",
    "\n",
    "Specifically, go back to simulating the solution to the harmonic oscillator and see what happens when you **increase** $\\omega_0$ from 20 to 80.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution(d, w0, t):\n",
    "    \"Defines the analytical solution to the under-damped harmonic oscillator problem above.\"\n",
    "    assert d < w0\n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*t)\n",
    "    exp = torch.exp(-d*t)\n",
    "    u = exp*2*A*cos\n",
    "    return u\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a standard fully-connected network in PyTorch\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2: Implement the ansatz formulation (20 marks)\n",
    "\n",
    "You should find that the PINN struggles to converge, even if the number of physics training points is increased.\n",
    "\n",
    "This is a harder problem for the PINN to solve, in part because of the **spectral bias** of neural networks, as well as the fact more training points are required.\n",
    "\n",
    "#### Approach: alternative \"ansatz\" formulation\n",
    "\n",
    "To speed up convergence, one way is to **assume something** about the solution. \n",
    "\n",
    "For example, suppose we know from our physics intuition that the solution is in fact sinusodial.\n",
    "\n",
    "Then, instead of having the PINN directly approximate the solution to the differential equation, i.e.\n",
    "\n",
    "$$\n",
    "u_{\\mathrm{PINN}}(t;\\theta) \\approx u(t)~,\n",
    "$$\n",
    "\n",
    "We instead use the PINN as part of a mathematical ansatz of the solution, i.e.\n",
    "\n",
    "$$\n",
    "\\hat u(t; \\theta, \\alpha, \\beta) = u_{\\mathrm{PINN}}(t;\\theta)  \\sin (\\alpha t + \\beta) \\approx u(t)~,\n",
    "$$\n",
    "\n",
    "where $\\alpha, \\beta$ are treated as additional learnable parameters.\n",
    "\n",
    "Comparing this ansatz to the exact solution\n",
    "\n",
    "$$\n",
    "u(t) = e^{-\\delta t}(2 A \\cos(\\phi + \\omega t))\n",
    "$$\n",
    "\n",
    "We see that now the PINN only needs to learn the exponential function, which should be a much easier problem.\n",
    "\n",
    "Again, autodifferentiation allows us to easily differentiate through this ansatz to train the PINN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Extend the inversion task (20 marks)\n",
    "\n",
    "See how far you can push the inversion task: can you discover $m$, $\\mu$ and $k$ simultaneously (and therefore, discover the entire underlying equation?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Solve the 1D wave equation (40 marks)\n",
    "\n",
    "Finally, we will solve the 1D (one space dimension plus time) wave equation using PINNs. The 1D wave equation is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2 u}{\\partial x^2}\n",
    "$$\n",
    "\n",
    "where $u(x, t)$ is the wave function, and $c$ is the wave speed.\n",
    "\n",
    "You will need to modify the PINN to handle the 1D wave equation and experiment with different hyperparameters to improve the convergence of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the impact of different physics sampling points, neural network architectures, and optimization algorithms on the performance of the PINN for solving the 1D wave equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Solves the 1-D Wave equation\n",
    "    d^2u          d^2 u\n",
    "    ----  = c^2 * -----\n",
    "    dt^2          dx^2   \n",
    "\n",
    "    for -1.0 < x < +1.0, and 0 < t\n",
    "\n",
    "    Boundary conditions:\n",
    "    u(x,0) = - sin(pi*x)\n",
    "    u(-1,t) = u(+1,t) = 0\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "# get boundary training points\n",
    "x1 = torch.stack([-torch.ones(40), torch.linspace(0,2,40)],-1)\n",
    "u1 = torch.zeros_like(x1[:,0:1])\n",
    "print(x1.shape, u1.shape)\n",
    "\n",
    "x2 = torch.stack([torch.ones(40), torch.linspace(0,2,40)],-1)\n",
    "u2 = torch.zeros_like(x2[:,0:1])\n",
    "print(x2.shape, u2.shape)\n",
    "\n",
    "x3 = torch.stack([torch.linspace(-1,1,40), torch.zeros(40)],-1)\n",
    "u3 = -torch.sin(np.pi*x3[:,0:1])\n",
    "print(x3.shape, u3.shape)\n",
    "\n",
    "# get physics loss sample points over full domain\n",
    "xs = [torch.linspace(-1,1,40), torch.linspace(0,2,40)]\n",
    "x_physics = torch.stack(torch.meshgrid(*xs, indexing='ij'), -1).view(-1, 2).requires_grad_(True)\n",
    "print(x_physics.shape)\n",
    "\n",
    "# get testing locations\n",
    "xs = [torch.linspace(-1,1,100), torch.linspace(0,2,100)]\n",
    "x_test = torch.stack(torch.meshgrid(*xs, indexing='ij'), -1).view(-1, 2)\n",
    "print(x_test.shape)\n",
    "    \n",
    "\n",
    "# define NN\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a fully-connected network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "c=1.0\n",
    "torch.manual_seed(123)\n",
    "model = FCN(2,1,64,4)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute the \"boundary loss\"\n",
    "    y1, y2, y3 = model(x1), model(x2), model(x3)\n",
    "    loss1 = torch.mean((y1-u1)**2) + torch.mean((y2-u2)**2) + torch.mean((y3-u3)**2)\n",
    "    \n",
    "    # compute the \"physics loss\"\n",
    "    u = model(x_physics)\n",
    "    dx  = torch.autograd.grad(u, x_physics, torch.ones_like(u), create_graph=True)[0]# computes du/dx and du/dt\n",
    "    dx, dt = dx[:,0:1], dx[:,1:2]\n",
    "    dx1dx = torch.autograd.grad(dx, x_physics, torch.ones_like(u), create_graph=True)[0]# computes d^2u/dx^2\n",
    "    dx1dx1 = dx1dx[:,0:1]\n",
    "    dt1dt = torch.autograd.grad(dt, x_physics, torch.ones_like(u), create_graph=True)[0]# computes d^2u/dt^2\n",
    "    dt1dt1 = dt1dt[:,1:2]\n",
    "    physics = (dt1dt1[:,0]) - (c * dx1dx1[:,0]) # computes the residual of the Wave eqn\n",
    "    loss2 = (0.1)*torch.mean(physics**2)\n",
    "    \n",
    "    # backpropagate joint loss\n",
    "    loss = loss1 + loss2 # add two loss terms together\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (i+1) % 1000 == 0: \n",
    "        y = model(x_test)\n",
    "        plt.figure()\n",
    "        plt.imshow(y.reshape(100,100).detach(), vmin=-1, vmax=1)\n",
    "        plt.xticks(np.linspace(0,100,5).astype(int), np.linspace(0,2,5))\n",
    "        plt.yticks(np.linspace(0,100,5).astype(int), np.linspace(-1,1,5))\n",
    "        plt.xlabel(\"t\"); plt.ylabel(\"x\")\n",
    "        plt.title(\"Training step: %i\"%(i+1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: BONUS - Solve the 2D wave equation (25 extra marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this paper for some hints: https://arxiv.org/pdf/2006.11894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Guidelines:\n",
    "- Format: Jupyter Notebook with annotations and text descriptions inline. Roughly 5-15 pages, including code and figures, if it were printed.\n",
    "- Deadline: **1 week from the assignment date.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sio209_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
