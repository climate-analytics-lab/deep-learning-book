{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning for Geo/Environmental sciences\n",
    "\n",
    "<center><img src=\"../logo_2.png\" alt=\"logo\" width=\"500\"/></center>\n",
    "\n",
    "<em>*Created with ChapGPT</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/climate-analytics-lab/sioc209-2024-sp/blob/main/sioc209-2024-sp/06_unsupervised_learning/11_dimensionality_reduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 14: Generative Models\n",
    "\n",
    " - [Recap](#Recap)\n",
    " - [Generative Models](#Generative-Models)\n",
    " - [Variational Autoencoders](#Variational-Autoencoders)\n",
    " - [Generative Adversarial Networks](#Generative-Adversarial-Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "In the last lecture we introduced unsupervised learning and discussed clustering algorithms. We learned about K-means clustering and hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As we discussed, unsupervised learning is a type of machine learning that looks for previously undetected patterns and structure in a dataset with no pre-existing labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile2Vec  - I think move this to next week\n",
    "\n",
    "Tile2Vec is a technique for learning visual representations of satellite imagery using unsupervised learning. The technique is based on the idea of learning a representation of the spatial context of the image tiles, rather than the content of the tiles themselves.\n",
    "\n",
    "Tile2Vec works by training a convolutional neural network to predict the spatial context of the image tiles. The network is trained using a contrastive loss function, which encourages the network to learn representations that are close together for similar tiles and far apart for dissimilar tiles.\n",
    "\n",
    "The result is a set of visual representations of the image tiles that capture the spatial context of the tiles. These representations can be used for a variety of tasks, such as image retrieval, image classification, and image segmentation.\n",
    "\n",
    "Tile2Vec is a powerful technique for learning visual representations of satellite imagery and has been shown to outperform other techniques for satellite image retrieval and classification.\n",
    "\n",
    "### Contrastive Learning\n",
    "\n",
    "Contrastive learning is a technique for learning representations of data by contrasting similar and dissimilar pairs of data points. The idea is to learn a representation that brings similar data points closer together in the embedding space and pushes dissimilar data points further apart.\n",
    "\n",
    "Contrastive learning is widely used in unsupervised learning and self-supervised learning, where the goal is to learn representations of data without the need for labeled data.\n",
    "\n",
    "The contrastive loss function is typically defined as the sum of two terms: a positive term that encourages similar data points to be close together in the embedding space, and a negative term that encourages dissimilar data points to be far apart.\n",
    "\n",
    "Mathematically, the contrastive loss function can be expressed as follows:\n",
    "\n",
    "$$\n",
    "L = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(f(x_i, x_i^+))}{\\exp(f(x_i, x_i^+)) + \\sum_{j=1}^{N} \\exp(f(x_i, x_j^-))}\n",
    "$$\n",
    "\n",
    "where $ N $ is the number of data points, $ x_i $ is a data point, $ x_i^+ $ is a similar data point, $ x_i^- $ is a dissimilar data point, and $ f $ is a function that maps the data points to the embedding space.\n",
    "\n",
    "The contrastive loss function encourages the network to learn representations that are close together for similar data points and far apart for dissimilar data points. This allows the network to learn a meaningful representation of the data that captures the underlying structure of the data.\n",
    "\n",
    "The tile2vec algorithm uses contrastive learning to learn visual representations of satellite imagery by contrasting similar and dissimilar image tiles. This is sometimes called a triplet loss, where the network is trained to minimize the distance between similar pairs of data points and maximize the distance between dissimilar pairs of data points:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^{N} \\max(0, \\alpha + d(f(x_i), f(x_i^+)) - d(f(x_i), f(x_i^-)))\n",
    "$$\n",
    "\n",
    "where $ d $ is a distance function, $ f $ is a function that maps the data points to the embedding space, $ x_i $ is a data point, $ x_i^+ $ is a similar data point, $ x_i^- $ is a dissimilar data point, and $ \\alpha $ is a margin that separates the similar and dissimilar pairs.\n",
    "\n",
    "We'll see an example of applying tile2vec to satellite imagery in the next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Models\n",
    "\n",
    "Generative models are a class of machine learning models that are used to generate new data samples from a given dataset. The goal of generative models is to learn the underlying distribution of the data and generate new samples that are similar to the original data.\n",
    "\n",
    "Generative models are widely used in a variety of applications, such as image generation, text generation, and music generation. They are also used in unsupervised learning to learn representations of data and generate new samples from the learned representations.\n",
    "\n",
    "There are many different types of generative models, including autoencoders, variational autoencoders, and generative adversarial networks. In this lecture, we'll focus on variational autoencoders and generative adversarial networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoders\n",
    "\n",
    "Variational autoencoders (VAEs) are a type of generative model that learn a probabilistic representation of the data. VAEs are based on the idea of encoding the data into a lower-dimensional latent space and then decoding the latent representation back into the original data space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow the nice MNIST tutorial here: https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks\n",
    "\n",
    "Generative adversarial networks (GANs) are a type of generative model that learn to generate new samples by training two neural networks: a generator and a discriminator. The generator network generates new samples, while the discriminator network tries to distinguish between real and generated samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "sio209_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
